{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c280298-ea09-4426-b36f-9311f60a1f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of dataset:\n",
      "\n",
      "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
      "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
      "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
      "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
      "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
      "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
      "\n",
      "   Longitude  MedHouseVal  \n",
      "0    -122.23        4.526  \n",
      "1    -122.22        3.585  \n",
      "2    -122.24        3.521  \n",
      "3    -122.25        3.413  \n",
      "4    -122.25        3.422  \n",
      "\n",
      "Dataset Shape: (20640, 9)\n",
      "\n",
      "Dataset Info:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   MedInc       20640 non-null  float64\n",
      " 1   HouseAge     20640 non-null  float64\n",
      " 2   AveRooms     20640 non-null  float64\n",
      " 3   AveBedrms    20640 non-null  float64\n",
      " 4   Population   20640 non-null  float64\n",
      " 5   AveOccup     20640 non-null  float64\n",
      " 6   Latitude     20640 non-null  float64\n",
      " 7   Longitude    20640 non-null  float64\n",
      " 8   MedHouseVal  20640 non-null  float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 1.4 MB\n",
      "None\n",
      "\n",
      "Checking Missing Values:\n",
      "\n",
      "MedInc         0\n",
      "HouseAge       0\n",
      "AveRooms       0\n",
      "AveBedrms      0\n",
      "Population     0\n",
      "AveOccup       0\n",
      "Latitude       0\n",
      "Longitude      0\n",
      "MedHouseVal    0\n",
      "dtype: int64\n",
      "\n",
      "Missing values handled (if any existed).\n",
      "\n",
      "Performing Feature Scaling using StandardScaler...\n",
      "\n",
      "Train-Test Split Done.\n",
      "Training Set Shape: (16512, 8)\n",
      "Testing Set Shape: (4128, 8)\n",
      "\n",
      "Explanation of Preprocessing Steps:\n",
      "1. Loaded dataset using fetch_california_housing().\n",
      "2. Converted dataset into pandas DataFrame.\n",
      "3. Checked and handled missing values (filled with mean if any).\n",
      "4. Split data into training and testing sets (80-20 split).\n",
      "5. Applied StandardScaler for feature scaling.\n",
      "   Scaling is necessary for algorithms like SVR and Linear Regression.\n",
      "   It ensures all features are on same scale.\n",
      "\n",
      "Applying Linear Regression...\n",
      "Linear Regression Explanation:\n",
      "Linear Regression models the relationship between features and target\n",
      "using a straight-line equation. Suitable for predicting continuous values.\n",
      "\n",
      "Applying Decision Tree Regressor...\n",
      "Decision Tree Explanation:\n",
      "Decision Tree splits the dataset into smaller subsets\n",
      "based on feature values. Good for capturing non-linear relationships.\n",
      "\n",
      "Applying Random Forest Regressor...\n",
      "Random Forest Explanation:\n",
      "Random Forest is an ensemble of multiple decision trees.\n",
      "It reduces overfitting and improves accuracy.\n",
      "\n",
      "Applying Gradient Boosting Regressor...\n",
      "Gradient Boosting Explanation:\n",
      "Gradient Boosting builds trees sequentially.\n",
      "Each new tree corrects the errors of previous trees.\n",
      "\n",
      "Applying Support Vector Regressor (SVR)...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# LOADING AND PREPROCESSING\n",
    "# Load dataset\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "# Convert into pandas DataFrame\n",
    "df = pd.DataFrame(housing.data, columns=housing.feature_names)\n",
    "df[\"MedHouseVal\"] = housing.target\n",
    "print(\"First 5 rows of dataset:\\n\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nDataset Shape:\", df.shape)\n",
    "print(\"\\nDataset Info:\\n\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nChecking Missing Values:\\n\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Handle Missing Values\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "print(\"\\nMissing values handled (if any existed).\")\n",
    "\n",
    "# Feature Scaling\n",
    "\n",
    "print(\"\\nPerforming Feature Scaling using StandardScaler...\\n\")\n",
    "\n",
    "X = df.drop(\"MedHouseVal\", axis=1)\n",
    "y = df[\"MedHouseVal\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Train-Test Split Done.\")\n",
    "print(\"Training Set Shape:\", X_train.shape)\n",
    "print(\"Testing Set Shape:\", X_test.shape)\n",
    "\n",
    "\n",
    "# Explanation of Preprocessing\n",
    "\n",
    "\n",
    "print(\"\\nExplanation of Preprocessing Steps:\")\n",
    "print(\"1. Loaded dataset using fetch_california_housing().\")\n",
    "print(\"2. Converted dataset into pandas DataFrame.\")\n",
    "print(\"3. Checked and handled missing values (filled with mean if any).\")\n",
    "print(\"4. Split data into training and testing sets (80-20 split).\")\n",
    "print(\"5. Applied StandardScaler for feature scaling.\")\n",
    "print(\"   Scaling is necessary for algorithms like SVR and Linear Regression.\")\n",
    "print(\"   It ensures all features are on same scale.\\n\")\n",
    "\n",
    "#  REGRESSION ALGORITHM IMPLEMENTATION \n",
    "\n",
    "results = []\n",
    "\n",
    "#  Linear Regression\n",
    "print(\"Applying Linear Regression...\")\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "y_pred_lr = lr.predict(X_test_scaled)\n",
    "\n",
    "print(\"Linear Regression Explanation:\")\n",
    "print(\"Linear Regression models the relationship between features and target\")\n",
    "print(\"using a straight-line equation. Suitable for predicting continuous values.\\n\")\n",
    "\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "results.append([\"Linear Regression\", mse_lr, mae_lr, r2_lr])\n",
    "\n",
    "\n",
    "# Decision Tree Regressor\n",
    "\n",
    "\n",
    "print(\"Applying Decision Tree Regressor...\")\n",
    "\n",
    "dt = DecisionTreeRegressor(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "\n",
    "print(\"Decision Tree Explanation:\")\n",
    "print(\"Decision Tree splits the dataset into smaller subsets\")\n",
    "print(\"based on feature values. Good for capturing non-linear relationships.\\n\")\n",
    "\n",
    "mse_dt = mean_squared_error(y_test, y_pred_dt)\n",
    "mae_dt = mean_absolute_error(y_test, y_pred_dt)\n",
    "r2_dt = r2_score(y_test, y_pred_dt)\n",
    "\n",
    "results.append([\"Decision Tree\", mse_dt, mae_dt, r2_dt])\n",
    "\n",
    "\n",
    "# Random Forest Regressor\n",
    "\n",
    "print(\"Applying Random Forest Regressor...\")\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Explanation:\")\n",
    "print(\"Random Forest is an ensemble of multiple decision trees.\")\n",
    "print(\"It reduces overfitting and improves accuracy.\\n\")\n",
    "\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "results.append([\"Random Forest\", mse_rf, mae_rf, r2_rf])\n",
    "\n",
    "#  Gradient Boosting Regressor\n",
    "\n",
    "print(\"Applying Gradient Boosting Regressor...\")\n",
    "\n",
    "gb = GradientBoostingRegressor(random_state=42)\n",
    "gb.fit(X_train, y_train)\n",
    "y_pred_gb = gb.predict(X_test)\n",
    "\n",
    "print(\"Gradient Boosting Explanation:\")\n",
    "print(\"Gradient Boosting builds trees sequentially.\")\n",
    "print(\"Each new tree corrects the errors of previous trees.\\n\")\n",
    "\n",
    "mse_gb = mean_squared_error(y_test, y_pred_gb)\n",
    "mae_gb = mean_absolute_error(y_test, y_pred_gb)\n",
    "r2_gb = r2_score(y_test, y_pred_gb)\n",
    "\n",
    "results.append([\"Gradient Boosting\", mse_gb, mae_gb, r2_gb])\n",
    "\n",
    "\n",
    "# Support Vector Regressor (SVR)\n",
    "\n",
    "print(\"Applying Support Vector Regressor (SVR)...\")\n",
    "\n",
    "svr = SVR()\n",
    "svr.fit(X_train_scaled, y_train)\n",
    "y_pred_svr = svr.predict(X_test_scaled)\n",
    "\n",
    "print(\"SVR Explanation:\")\n",
    "print(\"Support Vector Regressor tries to fit the best line within a margin.\")\n",
    "print(\"Works well for complex relationships but sensitive to scaling.\\n\")\n",
    "\n",
    "mse_svr = mean_squared_error(y_test, y_pred_svr)\n",
    "mae_svr = mean_absolute_error(y_test, y_pred_svr)\n",
    "r2_svr = r2_score(y_test, y_pred_svr)\n",
    "\n",
    "results.append([\"SVR\", mse_svr, mae_svr, r2_svr])\n",
    "\n",
    "\n",
    "\n",
    "#  MODEL EVALUATION AND COMPARISON \n",
    "\n",
    "print(\"\\nModel Evaluation Results:\\n\")\n",
    "\n",
    "results_df = pd.DataFrame(results, columns=[\"Model\", \"MSE\", \"MAE\", \"R2 Score\"])\n",
    "\n",
    "print(results_df)\n",
    "\n",
    "# Identify Best & Worst Model\n",
    "best_model = results_df.loc[results_df[\"R2 Score\"].idxmax()]\n",
    "worst_model = results_df.loc[results_df[\"R2 Score\"].idxmin()]\n",
    "\n",
    "print(\"\\nBest Performing Model:\")\n",
    "print(best_model)\n",
    "\n",
    "print(\"\\nWorst Performing Model:\")\n",
    "print(worst_model)\n",
    "\n",
    "print(\"\\nComparison Justification:\")\n",
    "print(\"Best model is selected based on highest R2 Score and lowest errors.\")\n",
    "print(\"Worst model is selected based on lowest R2 Score and higher errors.\")\n",
    "\n",
    "print(\"\\n================ FINAL SUMMARY ================\\n\")\n",
    "print(\"Dataset Used: California Housing Dataset from sklearn\")\n",
    "print(\"Algorithms Implemented:\")\n",
    "print(\"1. Linear Regression\")\n",
    "print(\"2. Decision Tree Regressor\")\n",
    "print(\"3. Random Forest Regressor\")\n",
    "print(\"4. Gradient Boosting Regressor\")\n",
    "print(\"5. Support Vector Regressor (SVR)\")\n",
    "print(\"\\nEvaluation Metrics Used:\")\n",
    "print(\"- Mean Squared Error (MSE)\")\n",
    "print(\"- Mean Absolute Error (MAE)\")\n",
    "print(\"- R2 Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4b871b-d3a4-4a62-9aaf-955598a40e66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
